{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import json\n",
    "\n",
    "a = tf.constant([1,2,3], tf.float32)\n",
    "y = tf.nn.moments(a, axes=[0])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fix_yahoo_finance as yf\n",
    "import pandas \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def downloadAndMerge(names):\n",
    "    downloaded = []\n",
    "    for n in names:\n",
    "        nv = yf.download(n)[['Close']]\n",
    "        nv.columns = [n]\n",
    "        downloaded.append(nv)\n",
    "        \n",
    "    merged = pandas.concat(downloaded, axis=1, join='outer')\n",
    "    x = merged.values \n",
    "    i = len(x) - 1\n",
    "    while i > 0:\n",
    "        if np.isnan(x[i]).any():\n",
    "            break\n",
    "        i-=1\n",
    "    print(merged.columns[merged.iloc[i].isna()][0])\n",
    "    print(merged.iloc[i].name)\n",
    "    merged = merged.iloc[i+1:].T\n",
    "    return downloaded, merged\n",
    "\n",
    "\n",
    "def getD(df):\n",
    "    base = 10\n",
    "    a = df.iloc[:, :-1]\n",
    "    b = df.iloc[:, 1:]\n",
    "    b.columns = a.columns = range(df.shape[1] - 1)\n",
    "    r = (b - a) / a\n",
    "    d = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                        np.add.accumulate(r * base, axis=1) + np.ones(r.shape) * base), axis=1)\n",
    "    return d \n",
    "\n",
    "\n",
    "def toWeek(df, start):\n",
    "    idx = datetime.strptime(start, '%b %d %Y')\n",
    "    week = []\n",
    "    names = []\n",
    "    while idx < datetime.now():\n",
    "        names.append(idx)\n",
    "        if idx in df.columns:\n",
    "            week.append(df[idx].values)\n",
    "        else:\n",
    "            for i in range(1, 7):\n",
    "                nidx = idx + timedelta(days=(i*-1))\n",
    "                if nidx in df.columns:\n",
    "                    week.append(df[nidx].values)\n",
    "                    break\n",
    "        idx = idx + timedelta(days=7)\n",
    "    \n",
    "    ndf = pandas.DataFrame(week).T\n",
    "    ndf.index = df.index\n",
    "    ndf.columns = names\n",
    "    return ndf\n",
    "\n",
    "\n",
    "def findDrop(s):\n",
    "    drop = 1 - s / np.maximum.accumulate(s)\n",
    "    i = np.argmax(drop) # end of the period\n",
    "    j = np.argmax(s[:i]) # start of period\n",
    "    print('max drawback {:0.2f}% {:0.2f} {:0.2f} {} {}'.format(drop[i] * 100, s[i], s[j], i, j))\n",
    "    jump = 1\n",
    "    while i + jump < len(s):\n",
    "        if s[i + jump] >= s[j]:\n",
    "            break\n",
    "        jump += 1\n",
    "    print('wait {} after max drop'.format(jump))\n",
    "    print('average drop', drop.mean())\n",
    "    pandas.DataFrame(drop).hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = ['SPY','EEM','QQQ','HYG','IWM','XLF','VXX','UVXY','EFA','FXI','EWZ','TLT','GLD','FEZ','SMH','USO','SLV','GDX','XLI','XLE','DIA','XRT','XOP','KRE','AAPL','BAC','BABA','TSLA','FB','AMZN','GE','AMD','MU','C','INTC','AABA','EA','JPM','F','NXPI','NFLX','TWTR','MSFT','FOXA','WYNN','GM','CAT','WFC','X','T','JD','PBR','QCOM','USB','AA','WMT','AAL','BA','CMCSA','BIDU','KMI','MS','MET','FCX','NVDA','M','SQ','GS','V','BK','DB']\n",
    "downloaded, merged = downloadAndMerge(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(downloaded)):\n",
    "    if downloaded[i].columns[0] == 'SNAP':\n",
    "        del downloaded[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(downloaded))\n",
    "print(len(search))\n",
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = getD(toWeek(merged, 'Nov 20 2015'))\n",
    "print(d.shape)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = d\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pandas.DataFrame(d * np.array([[0.05311488], [0.81805724]])).sum(axis=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "s = df.values[0]\n",
    "#s = 0.9 * d[0] + 0.1 * d[1]\n",
    "findDrop(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "base = 10\n",
    "threshold = 0.6\n",
    "\n",
    "df = pandas.read_csv('d.csv', index_col=0)\n",
    "df = df.filter(regex='[\\u4e00-\\u9fa5]', axis=0)\n",
    "a = df.iloc[:, :-1]\n",
    "b = df.iloc[:, 1:]\n",
    "b.columns = a.columns = range(df.shape[1] - 1)\n",
    "r = (b - a) / a\n",
    "p = 1 / np.linalg.norm(r, axis=1)\n",
    "r = (r.T * p).T.values\n",
    "l = r.shape[0]\n",
    "\n",
    "correlation = np.ones([l, l])\n",
    "for i in range(l):\n",
    "    for j in range(i + 1, l):\n",
    "        s = (r[i] * r[j]).sum()\n",
    "        correlation[i][j] = s\n",
    "        correlation[j][i] = s\n",
    "correlation[np.abs(correlation) > threshold] = 0\n",
    "correlation[np.logical_and(np.abs(correlation) <= threshold, correlation != 0)] = 1\n",
    "\n",
    "d = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                        np.add.accumulate(r * base, axis=1) + np.ones(r.shape) * base), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df.index.tolist().index('短期VIX指数期货ETN'))\n",
    "print(df.index.tolist().index('英伟达'))\n",
    "V = np.array([list(d[469]), list(d[646])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "#w = tf.get_variable(\"weight\", [V.shape[0], 1], tf.float32, initializer=tf.ones_initializer())\n",
    "v = tf.constant(V, tf.float32)\n",
    "s = tf.reduce_sum(w * v, axis=0)\n",
    "\n",
    "# regression loss\n",
    "def reg_loss(w, v):\n",
    "    a = tf.get_variable(\"a\", [1], tf.float32, initializer=tf.truncated_normal_initializer)\n",
    "    x = np.arange(V.shape[1])\n",
    "    y = a * x + 10\n",
    "    return tf.reduce_sum(tf.pow(s - y, 2))\n",
    "\n",
    "# drop loss\n",
    "length = V.shape[1]\n",
    "\n",
    "mask = np.ones([length,length], dtype=bool)\n",
    "zero = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(i):\n",
    "        mask[j][i] = 0\n",
    "\n",
    "def drop_loss(w, v):\n",
    "    b = tf.constant(mask)\n",
    "    y = tf.tile(s, [length])\n",
    "    y = tf.reshape(y, [length,length])\n",
    "    y = tf.where(b, y, np.zeros([length,length]))\n",
    "    y = tf.reduce_max(y, axis=1)\n",
    "    return tf.reduce_max(1 - s / y)\n",
    "\n",
    "key_loss = drop_loss(w, v)\n",
    "w_loss = tf.pow(tf.reduce_sum(tf.pow(w, 2)) - 1, 2)\n",
    "std_loss = 1 - tf.nn.moments(tf.abs(w), axes=[0])[1][0]\n",
    "total_loss = key_loss + w_loss + std_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train_op = optimizer.minimize(total_loss)\n",
    "\n",
    "output_w = None\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for step in range(10000000):\n",
    "        if step % 100 == 0:\n",
    "            print(step)\n",
    "            output_w = sess.run(w)\n",
    "            print('drop ', sess.run(key_loss))\n",
    "            print('not too big ', sess.run(w_loss))\n",
    "            print('look the same ', sess.run(std_loss))\n",
    "            print('total', sess.run(total_loss))\n",
    "        sess.run(train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = d[np.where(np.abs(output_w) > 0.1)[0]].sum(axis=0) / 15\n",
    "findDrop(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y = drop_loss(tf.constant([[0],[1]], tf.float32), tf.constant(V, tf.float32))\n",
    "    print(sess.run(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([[0.54],[0.36]])\n",
    "s = (w * V).sum(axis=0)\n",
    "s = s / s[0] * 10\n",
    "findDrop(s)\n",
    "findDrop(d[469])\n",
    "graph = np.concatenate([V, [s]], axis=0).T\n",
    "pandas.DataFrame(graph).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latest = np.load('lasttime.npy')\n",
    "print(latest[0:3])\n",
    "print(latest[-3:])\n",
    "\n",
    "for a in latest:\n",
    "    if 469 in a[0]:\n",
    "        print(a)\n",
    "        break\n",
    "\n",
    "dict = {}\n",
    "for a in latest:\n",
    "    for b in a[0]:\n",
    "        if b in dict:\n",
    "            dict[b] += 1\n",
    "        else:\n",
    "            dict[b] = 1\n",
    "x = []\n",
    "for key in dict:\n",
    "    x.append([key, dict[key]])\n",
    "x = sorted(x, key=lambda m: m[1], reverse=True)\n",
    "\n",
    "for y in x:\n",
    "    print(df.index[y[0]], y[0], y[1])\n",
    "\n",
    "for a in latest[0:10]:\n",
    "    print(list(df.index[a[0]]), a[1],a[2],a[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test By tiger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [154, 184, 210, 428, 469, 538]\n",
    "columns = list(np.array(df.index)[idx])\n",
    "print(columns)\n",
    "\n",
    "dates = df.columns.astype(np.float32)\n",
    "startDate = dates[0]\n",
    "dates = np.round((dates - startDate) / 3600 / 24 / 1000 / 7) + 1\n",
    "\n",
    "coridx = np.zeros([len(idx), len(idx)])\n",
    "for i in range(len(idx)):\n",
    "    for j in range(i):\n",
    "        coridx[i][j] = correlation[idx[i]][idx[j]]\n",
    "        coridx[j][i] = correlation[idx[j]][idx[i]]\n",
    "print(coridx)\n",
    "\n",
    "# basic info\n",
    "a = d[idx][:, 1:]\n",
    "b = d[idx][:, :-1]\n",
    "r = a - b\n",
    "contri= np.abs(r).mean(axis=1)\n",
    "contri = contri / contri.min()\n",
    "print(\"contribution: {}\".format(contri))\n",
    "\n",
    "graph = pandas.DataFrame(d[idx]).T\n",
    "graph.columns = columns \n",
    "graph.plot()\n",
    "d[idx].sum(axis=0)[-1]\n",
    "\n",
    "s = (d[idx]).sum(axis=0)\n",
    "print(\"percentage of total value: {}\".format(p[idx] / p[idx].sum() * 100))\n",
    "\n",
    "\n",
    "# regression \n",
    "s = s / len(idx)\n",
    "A, B = np.polyfit(dates, np.log(s), 1)\n",
    "print('A,B', A, B)\n",
    "y = np.exp(A * dates + B)\n",
    "last = s[0] < y[0]\n",
    "reg = 0\n",
    "for i in range(1, len(s)):\n",
    "    if (s[i] < y[i]) != last:\n",
    "        reg += 1\n",
    "        last = s[i] < y[i]\n",
    "print('revisit times: ', reg)\n",
    "\n",
    "\n",
    "# max drawback \n",
    "drop = 1 - s / np.maximum.accumulate(s)\n",
    "i = np.argmax(drop) # end of the period\n",
    "j = np.argmax(s[:i]) # start of period\n",
    "print('max drawback {:0.2f}% {:0.2f} {:0.2f} {} {}'.format(drop[i] * 100, s[i], s[j], i, j))\n",
    "print('average drop', drop.mean())\n",
    "pandas.DataFrame(drop).hist(bins=20)\n",
    "\n",
    "\n",
    "print(s[-1])\n",
    "print(dates[-1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dates, y)\n",
    "plt.plot(dates, s)\n",
    "plt.plot([i,j], [s[i], s[j]], 'o', color='Red', markersize=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test by yahoo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "df = None\n",
    "for f in glob('sss\\\\*.csv'):\n",
    "    name = f.split('\\\\')[1].split('.')[0]\n",
    "    if df is None:\n",
    "        df = pandas.read_csv(f, index_col=0)[['Adj Close']]\n",
    "        df.columns = [name]\n",
    "    else:\n",
    "        csv = pandas.read_csv(f, index_col=0)[['Adj Close']]\n",
    "        csv.columns = [name]\n",
    "        df = pandas.concat([df,csv], axis=1)\n",
    "        \n",
    "df = df.dropna().T\n",
    "print(df.shape)\n",
    "a = df.iloc[:, :-1]\n",
    "b = df.iloc[:, 1:]\n",
    "b.columns = a.columns\n",
    "r = (((b - a) / a).T * p[idx] ).T\n",
    "r = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                    np.add.accumulate(r, axis=1) + np.ones(r.shape) * base), axis=1).T\n",
    "r = pandas.DataFrame(r)\n",
    "r.index = df.columns.astype(np.datetime64)\n",
    "r.columns = df.index\n",
    "r.plot(figsize=(16, 9))\n",
    "print(r.shape)\n",
    "\n",
    "y2 = r.sum(axis=1)\n",
    "#plt.figure(figsize=(16, 9))\n",
    "plt.plot(df.columns.astype(np.datetime64), y2 / len(idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test random output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "dist = []\n",
    "n = 6\n",
    "for i in range(100000):\n",
    "    choice = random.sample(range(d.shape[0]), n)\n",
    "    bad = True\n",
    "    while bad:\n",
    "        bad = False\n",
    "        for k in range(len(choice)):\n",
    "            for l in range(k):\n",
    "                if np.abs(cor[choice[k]][choice[l]]) > 0.75:\n",
    "                    bad = True\n",
    "                    break\n",
    "            if bad:\n",
    "                break\n",
    "        if bad:\n",
    "            choice = random.sample(range(d.shape[0]), n)\n",
    "\n",
    "    s = d[choice].sum(axis=0)\n",
    "    s = s / n\n",
    "    m = s.mean()\n",
    "    s = s / m\n",
    "    x = np.arange(len(s)) + 1\n",
    "    a, b = np.polyfit(x, np.log(s), 1)\n",
    "    y = np.exp(a * x + b)\n",
    "\n",
    "    # reg times\n",
    "    last = s[0] < y[0]\n",
    "    reg = 0\n",
    "    regDist = [0]\n",
    "    for i in range(1, len(s)):\n",
    "        if (s[i] < y[i]) != last:\n",
    "            regDist.append(i)\n",
    "            reg += 1\n",
    "            last = s[i] < y[i]\n",
    "\n",
    "    # reg distribution\n",
    "    regDist = np.array(regDist)\n",
    "    regStd = (regDist[1:] - regDist[:-1]).std()\n",
    "    dist.append(regStd)\n",
    "    \n",
    "pandas.DataFrame(dist).hist(bins=1000)\n",
    "pandas.qcut(dist,  [0, 0.05, 0.1, 0.25, 0.5, 0.75, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weekly data and clean into d.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "df = None\n",
    "for f in glob('D:\\\\work\\\\main\\\\IB\\\\*_week.csv'):\n",
    "    if df is None:\n",
    "        df = pandas.read_csv(f, index_col=0).T\n",
    "    else:\n",
    "        df = pandas.concat([df,pandas.read_csv(f, index_col=0).T], axis=1)\n",
    "\n",
    "d = df.iloc[-112:-1,:]\n",
    "d = d.dropna(axis=1,how='any').astype('float32').T\n",
    "d.to_csv('d.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "daily = None\n",
    "for f in glob('D:\\\\work\\\\main\\\\IB\\\\*_day.csv'):\n",
    "    if daily is None:\n",
    "        daily = pandas.read_csv(f, index_col=0).T\n",
    "    else:\n",
    "        daily = pandas.concat([daily,pandas.read_csv(f, index_col=0).T], axis=1)\n",
    "daily.to_csv('day.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test by day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "daily = pandas.read_csv('day.csv', index_col=0)[columns].T\n",
    "print(columns)\n",
    "moneyNeeded = 100 / (p[idx]/p[idx].sum()/daily.T.iloc[-1,:].values)[2]\n",
    "tobuy = np.round(moneyNeeded * p[idx]/p[idx].sum() /  daily.T.iloc[-1,:].values)\n",
    "moneyNeeded = tobuy * daily.T.iloc[-1,:].values\n",
    "print('shares ', str(tobuy), tobuy.sum(), moneyNeeded)\n",
    "moneyNeeded = moneyNeeded.sum()\n",
    "print(moneyNeeded)\n",
    "\n",
    "a = daily.iloc[:, :-1]\n",
    "b = daily.iloc[:, 1:]\n",
    "a.columns = b.columns\n",
    "r = ((b / a - 1).T * p[idx] ).T\n",
    "print(r.shape)\n",
    "\n",
    "dates = daily.columns.astype(np.float32)\n",
    "dates = np.round((dates - startDate) / 3600 / 24 / 1000) / 7 + 1\n",
    "base = 10.4\n",
    "r = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                    np.add.accumulate(r, axis=1) + np.ones(r.shape) * base), axis=1).T\n",
    "r = pandas.DataFrame(r)\n",
    "r.columns = columns\n",
    "r.index = dates\n",
    "r.plot(figsize=(16,9))\n",
    "\n",
    "y = np.exp(A * dates + B) * moneyNeeded / 10\n",
    "y2 = r.sum(axis=1) / len(columns) * moneyNeeded / 10\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(dates, y)\n",
    "plt.plot(dates, y2)\n",
    "#plt.plot(111, np.exp(A * 111 + B), marker='o', color='r', ls='')\n",
    "#y2[-1] / y[-1] - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
