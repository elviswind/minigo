{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import json\n",
    "\n",
    "a = tf.constant([1,3,4], tf.float32)\n",
    "b = tf.constant([1.1,1.2,1.3], tf.float32)\n",
    "\n",
    "\n",
    "b = tf.reduce_sum(tf.where(tf.abs(a) > 1, np.ones(a.shape), np.zeros(a.shape)))\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import fix_yahoo_finance as yf\n",
    "import pandas \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os.path\n",
    "\n",
    "def downloadAndMerge(names):\n",
    "    downloaded = []\n",
    "    for n in names:\n",
    "        csv = 'csv/' + n + '.csv'\n",
    "        print(n)\n",
    "        temp = None\n",
    "        if os.path.isfile(csv):\n",
    "            temp = pandas.read_csv(csv, index_col=0)\n",
    "        else:\n",
    "            temp = yf.download(n)\n",
    "            temp.to_csv(csv)\n",
    "        nv = temp[['Close']]\n",
    "        nv.columns = [n]\n",
    "        downloaded.append(nv)\n",
    "    \n",
    "    for i in downloaded:\n",
    "        if i.index.dtype != 'datetime64[ns]':\n",
    "            i.index = i.index.astype('datetime64')\n",
    "    \n",
    "    merged = pandas.concat(downloaded, axis=1, join='outer')\n",
    "    x = merged.values \n",
    "    i = len(x) - 1\n",
    "    while i > 0:\n",
    "        if np.isnan(x[i]).any():\n",
    "            break\n",
    "        i-=1\n",
    "    print(merged.columns[merged.iloc[i].isna()][0])\n",
    "    print(merged.iloc[i].name)\n",
    "    merged = merged.iloc[i+1:].T\n",
    "    return downloaded, merged\n",
    "\n",
    "\n",
    "def getD(df):\n",
    "    base = 10\n",
    "    a = df.iloc[:, :-1]\n",
    "    b = df.iloc[:, 1:]\n",
    "    b.columns = a.columns = range(df.shape[1] - 1)\n",
    "    r = (b - a) / a\n",
    "    d = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                        np.add.accumulate(r * base, axis=1) + np.ones(r.shape) * base), axis=1)\n",
    "    return d \n",
    "\n",
    "\n",
    "def toWeek(df, start):\n",
    "    idx = datetime.strptime(start, '%b %d %Y')\n",
    "    week = []\n",
    "    names = []\n",
    "    while idx <= df.columns[-1]:\n",
    "        names.append(idx)\n",
    "        if idx in df.columns:\n",
    "            week.append(df[idx].values)\n",
    "        else:\n",
    "            found = False\n",
    "            for i in range(1, 7):\n",
    "                nidx = idx + timedelta(days=(i*-1))\n",
    "                if nidx in df.columns:\n",
    "                    week.append(df[nidx].values)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                week.append(np.empty(df[idx].shape))\n",
    "        idx = idx + timedelta(days=7)\n",
    "    \n",
    "    ndf = pandas.DataFrame(week).T\n",
    "    ndf.index = df.index\n",
    "    ndf.columns = names\n",
    "    return ndf\n",
    "\n",
    "\n",
    "def findDrop(s, debug=True):\n",
    "    drop = 1 - s / np.maximum.accumulate(s)\n",
    "    i = np.argmax(drop) # end of the period\n",
    "    j = np.argmax(s[:i]) # start of period\n",
    "    jump = 1\n",
    "    while i + jump < len(s):\n",
    "        if s[i + jump] >= s[j]:\n",
    "            break\n",
    "        jump += 1\n",
    "        \n",
    "    if debug:\n",
    "        print('max drawback {:0.2f}%, from {:0.2f} to {:0.2f}'.format(drop[i] * 100, s[j], s[i]))    \n",
    "        print('wait {} after max drop'.format(jump))\n",
    "        print('drop lasting {}'.format(i - j))\n",
    "        print('average drop', drop.mean())\n",
    "    #pandas.DataFrame(drop).hist(bins=20)\n",
    "    return drop[i] * 100, drop.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "# regression loss\n",
    "def reg_loss(s, v):\n",
    "    a = tf.get_variable(\"a\", [1], tf.float32, initializer=tf.constant_initializer(0))\n",
    "    x = np.arange(int(v.shape[1]))\n",
    "    y = a * x + 10\n",
    "    return tf.reduce_sum(tf.pow(s - y, 2)) / int(y.shape[0]) / 10000, a\n",
    "\n",
    "def drop_loss(s, v):\n",
    "    length = v.shape[1]\n",
    "    mask = np.ones([length,length], dtype=bool)\n",
    "    zero = np.zeros([length,length])\n",
    "    for i in range(length):\n",
    "        for j in range(i):\n",
    "            mask[j][i] = 0\n",
    "    \n",
    "    b = tf.constant(mask)\n",
    "    y = tf.tile(s, [length])\n",
    "    y = tf.reshape(y, [length,length])\n",
    "    y = tf.where(b, y, np.full([length,length], np.NINF))\n",
    "    y = tf.reduce_max(y, axis=1)\n",
    "    return tf.reduce_max(1 - s / y)\n",
    "\n",
    "def anaTop(top, d, w, debug):\n",
    "    x = np.abs(w.T[0])\n",
    "    x.sort()\n",
    "    selected = np.where(np.abs(w) > x[-1 * top])[0]\n",
    "    if len(selected) > 0:\n",
    "        t = d[selected] * w[selected]\n",
    "        s = t.sum(axis=0)\n",
    "        s = s / s[0] * 10\n",
    "        drop, meandrop = findDrop(s, False)\n",
    "\n",
    "        x = np.arange(s.shape[0])\n",
    "        a, b = np.polyfit(x, s, 1)\n",
    "        y = b + a * x\n",
    "        if debug:\n",
    "            print('slope {}, fit loss {}'.format(a, (np.power(s - y, 2)).sum() / y.shape[0]))\n",
    "            print(merged.index[selected].tolist())\n",
    "            print(w[selected].T)\n",
    "        return drop, meandrop, selected, a\n",
    "    else:\n",
    "        return 1, 1, 1, 0\n",
    "\n",
    "def getW(V, debug):\n",
    "    w = tf.get_variable(\"weight\", [V.shape[0], 1], tf.float32, initializer=tf.ones_initializer())\n",
    "    v = tf.constant(V, tf.float32)\n",
    "    s = tf.reduce_sum(w * v, axis=0)\n",
    "\n",
    "    rl, a = reg_loss(s, v)\n",
    "    losses = [drop_loss(s, v), rl]\n",
    "    key_loss = sum(losses)\n",
    "    w_loss = tf.pow(tf.reduce_sum(tf.pow(w, 2)) - 1, 2)\n",
    "    std_loss = 1 - 20 * tf.nn.moments(tf.abs(w), axes=[0])[1][0]\n",
    "    #std_loss = 0.01 * tf.cast(tf.reduce_sum(tf.where(tf.abs(w) > 0.1, np.ones(w.shape), np.zeros(w.shape))), tf.float32)\n",
    "    total_loss = key_loss + w_loss + std_loss\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(0.002)\n",
    "    train_op = optimizer.minimize(total_loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        start_time = datetime.now()\n",
    "        for step in range(10000000):\n",
    "            if step % 1000 == 0:\n",
    "                output_w = sess.run(w)\n",
    "                drop, meandrop, selected, slope = anaTop(6, V, output_w, debug)\n",
    "                if (datetime.now() - start_time).seconds > 180:\n",
    "                    print('took too much time, abort, drop {}, meandrop {}'.format(drop, meandrop))\n",
    "                    return [], []\n",
    "                if debug:\n",
    "                    print(step)\n",
    "                    print('a ', sess.run(a))\n",
    "                    for l in losses:\n",
    "                        print('losses ', sess.run(l))\n",
    "                    print('not too big ', sess.run(w_loss))\n",
    "                    print('look the same ', sess.run(std_loss))\n",
    "                    print('total', sess.run(total_loss))\n",
    "                    print('drop {} meandrop {}'.format(drop, meandrop))\n",
    "\n",
    "                if drop < 4 and meandrop < 0.008:\n",
    "                    return selected, (output_w[selected] / np.absolute(output_w[selected]).sum()).T[0]\n",
    "\n",
    "            sess.run(train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search = ['SPY','EEM','QQQ','HYG','IWM','XLF','VXX','UVXY','EFA','FXI','EWZ','TLT','GLD','FEZ','SMH','USO','SLV','GDX','XLI','XLE','DIA','XRT','XOP','KRE','AAPL','BAC','BABA','TSLA','FB','AMZN','GE','AMD','MU','C','INTC','AABA','EA','JPM','F','NXPI','NFLX','TWTR','MSFT','FOXA','WYNN','GM','CAT','WFC','X','T','JD','PBR','QCOM','USB','AA','WMT','AAL','BA','CMCSA','BIDU','KMI','MS','MET','FCX','NVDA','M','SQ','GS','V','BK','DB']\n",
    "search = ['SPY','AAPL','AMZN','QQQ','NFLX','MSFT','KEYS','TSLA','IWM','GOOG','EEM','GOOGL','FB','BABA','AMD','NVDA','BRK-B','XLF','IVV','SBUX','EFA','XOM','BKNG','XLI','SQ','GE','BAC','IYR','XLU','INTC','JPM','PG','XLP','IBM','EWZ','ATVI','CVX','HYG','WFC','C','VXX','XLK','FXI','DIS','XLE','MU','MRK','PFE','V','UNH','EMB','MCD','ABBV','QCOM','T','LLY','BA','CSCO','KO','JNJ','LGND','IEMG','WMT','ADBE','UNP','GLD','VZ','DIA','CMCSA','LIN','HD','XLV','UTX','XOP','TQQQ','ORCL','CME','CRM','BIDU','HON','TWTR','MA','RHT','CAT','SMH','ABT','AVGO','PEP','SYY','TXN','COST','GS','MDY','GDX','LQD','MS','MMM','OXY','IEFA','NKE','VWO','KHC','TLT','VNQ','EOG','DWDP','AMGN','XLY','LMT','WBA','VOO','CVS','CL','MO','SLB','VTI','RTN','VEA','GD','BDX','XLB','GILD','SQQQ','TEVA','PM','GM','EL','EWJ','AAL','ISRG','MCHI','DGAZ','F','PYPL','EA','TVIX','IJH','CSX','IJR','COF','MDT','KRE','NOC','ECA','AMT','AGG','NEE','BMY','ACHC','NXPI','STX','MET','NWL','CELG','COP','PBR','MPC','CMG','SCHW','TSM','SPLK','JNK','TJX','LRCX','ULTA','BIIB','APC','LOW','STZ','HAL','LUV','EBAY','MTUM','EMR','WCG','AIG','BLK','CGC','TGT','PNC','MDLZ','ROKU','SHV','VLO','CCI','BAX','ALGN','XBI','BKLN','HRS','MAR','REGN','CI','DAL','INTU','NSC','ZTS','ANTM','WTW','USB','WDC','PLCE','BP','W','EW','AXP','SHW','COG','EXC','EQIX','EWT','WMB','FDX','NVS','AGN','HCA','ABMD','SPOT','CZR','PH','LLL','ACN','ETN','LVS','AMAT','SYMC','TDOC','IWD','USO','TMO','M','UPS','ILMN','GPC','VRSN','DRI','DUK','X','CHTR','USFD','UNG','JD','WDAY','FOXA','ADP','GIS','UGAZ','BBT','NOW','FDC','CAG','BIL','IEF','UVXY','TWLO','UAL','PSA','WYNN','SO','MYL','ANET','INDA','D','K','AKAM','APD','CIEN','ORLY','HES','GDXJ','AABA','KLAC','BK','ESRX','EWY','DE','IQV','PSX','EWW','KSS','NUE','FEZ','AET','WM','EXPE','XRT','FLOT','RSX','IWO','DXC','BBY','UAA','IP','TDG','ICE','CLX','YUM','FMC','CTSH','LULU','FTNT','PCG','DLR','KR','SAGE','MSI','IWB','RL','RACE','TNA','KEY','DHR','SWKS','PRU','VALE','SPGI','GRUB','CXO','CB','AAP','PXD','MCHP','SRE','DHI','CMI','NFX','IGV','BHC','DVN','TTWO','CHD','SDS','ROST','XLNX','IWF','SHY','MLM','AME','VTV','TYL','KMI','CNC','NTES','URI','STT','HLT','TMUS','VCSH','BX','MRO','DG','RDS-A','APTV','ADI','SPG','ABX','OMC','SWK','AMRN','VIG','WPC','VMC','BRK-A','APH','DXCM','NOV','ITUB','ADM','GOVT','QRVO','LYB','QID','WEC','TEL','PE','BSX','HPQ','SHOP','OLED','PBYI','VO','HUM','VIAB','ESS','UPRO','VST','FISV','KMB','CHK','AMP','XRAY','ET','EZU','HCP','MFC','LEN','CCL','PANW','FE','PAYX','XEL','PNW','JCI','SYK','MCK','FLR','NRZ','OHI','IWN','AZN','AEP','PEG','ED','EXAS','FSLR','ROP','SWN','TTD','CTL','ALL','GWW','COL','RRC','MCO','PPG','CMA','SYF','WP','OKE','HBAN','GDDY','STI','WRK','VFC','XPO','NBL','OIH','A','PGR','APA','VEEV','ENB','NRG','SPXU','ADSK','FANG','FAST','NCLH','CF','MHK','EQT','ALXN','CBS','MOH','IBB','SPLV','HRL','FLT','SBAC','BLL','MMI','SSO','AMLP','FOX','SCZ','MGM','CE','HOG','PLD','SRPT','SIRI','SJM','MAS','DLTR','LB','DPZ','ACWI','XEC','TPR','BND','RCL','WBT','IAC','DISCA','KORS','ITW','TLRY','MKC','EZA','EXPD','DTE','BBD','NTR','MTCH','IFF','CMS','RF','VRTX','GPN','AVB','TRV','NEM','AZO','MNST','DVA','MOS','ZBH','WLTW','MELI','HST','TRIP','ARNC','FITB','AES','SIVB','FL','DFS','MTB','SHPG','AFL','JBGS','TAP','TIP','SOXX','XLRE','LEA','BHGE','BURL','TRGP','BUD','NTAP','KDP','EIX','NUGT','LNC','HSIC','IR','REZI','WU','HSY','ECL','HYLB','MUB','LABU','CTXS','PBR-A','EPD','CRI','CLR','RPM','IDXX','IPG','SNA','SPTM','IAU','BG','ABEV','SPXL','JBHT','TAL','RH','ETR','LH','TIF','SH','HDV','MXIM','FCX','TSN','EXR','NVR','JWN','ON','NBIX','SPXS','VGK','BHP','TFI','GLW','CTAS','IVW','O','PACB','USMV','HBI','WELL','PHM','PPL','HAS','GG','CPT','GDI','QLD','GSK','EXEL','Z','VXF','FCE-A','MSG','WPX','HIG','WY','JNPR','ANSS','XLC','ZION','BHF','WLL','BF-B','WB','YUMC','VOD','VCIT','VTR','HIIQ','KWEB','BLUE','AR','CHRW','MTD','ROK','TOL','WEN','FTV','WAT','GGB','PTC','WEX','WSM','MRVL','DKS','SCHO','VUG','ULTI','IVZ','SEAS','MBB','EFX','EMN','ALK','CNP','BSV','ABC','CP','CFG','FIS','PAYC','MSCI','SCHF','IVE','GLNG','CDW','SEE','BR','RIG','CAH','VER','RJF','TZA','PII','CPB','TD','AOS','UA','SNAP','RIO','EWH','IQ','VRSK','HRC','HPE','LNG','OSK','CLF','EQR','DATA','VT','CTRP','MPW','RDS-B','DVMT','TRU','ETFC','ASML','KBE','FFIV','CWB','TSCO','PCAR','AMED','WHR','VAR','BXP','SU','OLLI','JAZZ','HFC','L','S']\n",
    "downloaded, merged = downloadAndMerge(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(downloaded)):\n",
    "    if downloaded[i].columns[0] == 'SNAP':\n",
    "        del downloaded[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in downloaded:\n",
    "    if i.index.dtype != 'datetime64[ns]':\n",
    "        i.index = i.index.astype('datetime64')\n",
    "        \n",
    "merged = pandas.concat(downloaded, axis=1, join='outer')\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = toWeek(merged.T, 'Jan 01 1999').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 30 \n",
    "pool = None\n",
    "height = 1000000\n",
    "def update(names, w, i):\n",
    "    global pool\n",
    "    global height \n",
    "    global step \n",
    "    entry = merged[names].iloc[i].values\n",
    "    if pool is not None:\n",
    "        now = merged[pool[0]].iloc[i].values\n",
    "        old = pool[2]\n",
    "        c = now / old - 1\n",
    "        change = c * pool[1] * height\n",
    "        height = change.sum() + height\n",
    "        print('change {}, height {}'.format(c, height))\n",
    "\n",
    "    pool = [names, w, merged[names].iloc[i].values]\n",
    "\n",
    "def clear(i):\n",
    "    global pool\n",
    "    global height \n",
    "    global step \n",
    "    if pool is not None:\n",
    "        now = merged[pool[0]].iloc[i].values\n",
    "        old = pool[2]\n",
    "        c = now / old - 1\n",
    "        change = c * pool[1] * height\n",
    "        height = change.sum() + height\n",
    "        print('change {}, height {}'.format(c, height))\n",
    "    pool = None\n",
    "\n",
    "for i in range(30, merged.shape[0]):\n",
    "    tf.reset_default_graph()\n",
    "    temp = merged.iloc[i-step:i, :].dropna(axis=1).T\n",
    "    print('i is {}, feed data from {} to {}'.format(i, temp.columns[0], temp.columns[-1]))\n",
    "    d = getD(temp)\n",
    "    selected, w = getW(d, False)\n",
    "    if len(selected) > 0:\n",
    "        names = temp.index[selected].tolist()\n",
    "        print('decide to have {} {} at {}'.format(names, w, merged.index[i]))\n",
    "        update(names, w, i)\n",
    "    else:\n",
    "        clear(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "100000 * w / merged.iloc[:, 40].values[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = getD(toWeek(merged, 'Nov 20 2015'))\n",
    "print(d.shape)\n",
    "V = d\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pandas.DataFrame(d * np.array([[0.05311488], [0.81805724]])).sum(axis=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "s = df.values[0]\n",
    "#s = 0.9 * d[0] + 0.1 * d[1]\n",
    "findDrop(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "base = 10\n",
    "threshold = 0.6\n",
    "\n",
    "df = pandas.read_csv('d.csv', index_col=0)\n",
    "df = df.filter(regex='[\\u4e00-\\u9fa5]', axis=0)\n",
    "a = df.iloc[:, :-1]\n",
    "b = df.iloc[:, 1:]\n",
    "b.columns = a.columns = range(df.shape[1] - 1)\n",
    "r = (b - a) / a\n",
    "p = 1 / np.linalg.norm(r, axis=1)\n",
    "r = (r.T * p).T.values\n",
    "l = r.shape[0]\n",
    "\n",
    "correlation = np.ones([l, l])\n",
    "for i in range(l):\n",
    "    for j in range(i + 1, l):\n",
    "        s = (r[i] * r[j]).sum()\n",
    "        correlation[i][j] = s\n",
    "        correlation[j][i] = s\n",
    "correlation[np.abs(correlation) > threshold] = 0\n",
    "correlation[np.logical_and(np.abs(correlation) <= threshold, correlation != 0)] = 1\n",
    "\n",
    "d = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                        np.add.accumulate(r * base, axis=1) + np.ones(r.shape) * base), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected, w = getW(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = (V[selected] * w).sum(axis=0)\n",
    "findDrop(s)\n",
    "x = np.arange(s.shape[0])\n",
    "y = 0.1139553 * x + 10\n",
    "\n",
    "s = (V[selected] * w).sum(axis=0)\n",
    "x = np.arange(s.shape[0])\n",
    "a, b = np.polyfit(x, s, 1)\n",
    "y = b + a * x\n",
    "print((np.power(s - y, 2)).sum() / y.shape[0])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, s)\n",
    "#plt.plot([i,j], [s[i], s[j]], 'o', color='Red', markersize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outer = pandas.concat(downloaded, axis=1, join='outer')\n",
    "outer = outer[merged.index[selected]]\n",
    "x = outer.values \n",
    "i = len(x) - 1\n",
    "while i > 0:\n",
    "    if np.isnan(x[i]).any():\n",
    "        break\n",
    "    i-=1\n",
    "print(outer.columns[outer.iloc[i].isna()][0])\n",
    "print(outer.iloc[i].name)\n",
    "outer = outer.iloc[i+1:].T \n",
    "s = (getD(outer) * w).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "findDrop(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y = drop_loss(tf.constant([[0],[1]], tf.float32), tf.constant(V, tf.float32))\n",
    "    print(sess.run(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([[0.54],[0.36]])\n",
    "s = (w * V).sum(axis=0)\n",
    "s = s / s[0] * 10\n",
    "findDrop(s)\n",
    "findDrop(d[469])\n",
    "graph = np.concatenate([V, [s]], axis=0).T\n",
    "pandas.DataFrame(graph).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latest = np.load('lasttime.npy')\n",
    "print(latest[0:3])\n",
    "print(latest[-3:])\n",
    "\n",
    "for a in latest:\n",
    "    if 469 in a[0]:\n",
    "        print(a)\n",
    "        break\n",
    "\n",
    "dict = {}\n",
    "for a in latest:\n",
    "    for b in a[0]:\n",
    "        if b in dict:\n",
    "            dict[b] += 1\n",
    "        else:\n",
    "            dict[b] = 1\n",
    "x = []\n",
    "for key in dict:\n",
    "    x.append([key, dict[key]])\n",
    "x = sorted(x, key=lambda m: m[1], reverse=True)\n",
    "\n",
    "for y in x:\n",
    "    print(df.index[y[0]], y[0], y[1])\n",
    "\n",
    "for a in latest[0:10]:\n",
    "    print(list(df.index[a[0]]), a[1],a[2],a[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test By tiger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [154, 184, 210, 428, 469, 538]\n",
    "columns = list(np.array(df.index)[idx])\n",
    "print(columns)\n",
    "\n",
    "dates = df.columns.astype(np.float32)\n",
    "startDate = dates[0]\n",
    "dates = np.round((dates - startDate) / 3600 / 24 / 1000 / 7) + 1\n",
    "\n",
    "coridx = np.zeros([len(idx), len(idx)])\n",
    "for i in range(len(idx)):\n",
    "    for j in range(i):\n",
    "        coridx[i][j] = correlation[idx[i]][idx[j]]\n",
    "        coridx[j][i] = correlation[idx[j]][idx[i]]\n",
    "print(coridx)\n",
    "\n",
    "# basic info\n",
    "a = d[idx][:, 1:]\n",
    "b = d[idx][:, :-1]\n",
    "r = a - b\n",
    "contri= np.abs(r).mean(axis=1)\n",
    "contri = contri / contri.min()\n",
    "print(\"contribution: {}\".format(contri))\n",
    "\n",
    "graph = pandas.DataFrame(d[idx]).T\n",
    "graph.columns = columns \n",
    "graph.plot()\n",
    "d[idx].sum(axis=0)[-1]\n",
    "\n",
    "s = (d[idx]).sum(axis=0)\n",
    "print(\"percentage of total value: {}\".format(p[idx] / p[idx].sum() * 100))\n",
    "\n",
    "\n",
    "# regression \n",
    "s = s / len(idx)\n",
    "A, B = np.polyfit(dates, np.log(s), 1)\n",
    "print('A,B', A, B)\n",
    "y = np.exp(A * dates + B)\n",
    "last = s[0] < y[0]\n",
    "reg = 0\n",
    "for i in range(1, len(s)):\n",
    "    if (s[i] < y[i]) != last:\n",
    "        reg += 1\n",
    "        last = s[i] < y[i]\n",
    "print('revisit times: ', reg)\n",
    "\n",
    "\n",
    "# max drawback \n",
    "drop = 1 - s / np.maximum.accumulate(s)\n",
    "i = np.argmax(drop) # end of the period\n",
    "j = np.argmax(s[:i]) # start of period\n",
    "print('max drawback {:0.2f}% {:0.2f} {:0.2f} {} {}'.format(drop[i] * 100, s[i], s[j], i, j))\n",
    "print('average drop', drop.mean())\n",
    "pandas.DataFrame(drop).hist(bins=20)\n",
    "\n",
    "\n",
    "print(s[-1])\n",
    "print(dates[-1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dates, y)\n",
    "plt.plot(dates, s)\n",
    "plt.plot([i,j], [s[i], s[j]], 'o', color='Red', markersize=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test by yahoo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "df = None\n",
    "for f in glob('sss\\\\*.csv'):\n",
    "    name = f.split('\\\\')[1].split('.')[0]\n",
    "    if df is None:\n",
    "        df = pandas.read_csv(f, index_col=0)[['Adj Close']]\n",
    "        df.columns = [name]\n",
    "    else:\n",
    "        csv = pandas.read_csv(f, index_col=0)[['Adj Close']]\n",
    "        csv.columns = [name]\n",
    "        df = pandas.concat([df,csv], axis=1)\n",
    "        \n",
    "df = df.dropna().T\n",
    "print(df.shape)\n",
    "a = df.iloc[:, :-1]\n",
    "b = df.iloc[:, 1:]\n",
    "b.columns = a.columns\n",
    "r = (((b - a) / a).T * p[idx] ).T\n",
    "r = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                    np.add.accumulate(r, axis=1) + np.ones(r.shape) * base), axis=1).T\n",
    "r = pandas.DataFrame(r)\n",
    "r.index = df.columns.astype(np.datetime64)\n",
    "r.columns = df.index\n",
    "r.plot(figsize=(16, 9))\n",
    "print(r.shape)\n",
    "\n",
    "y2 = r.sum(axis=1)\n",
    "#plt.figure(figsize=(16, 9))\n",
    "plt.plot(df.columns.astype(np.datetime64), y2 / len(idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test random output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "dist = []\n",
    "n = 6\n",
    "for i in range(100000):\n",
    "    choice = random.sample(range(d.shape[0]), n)\n",
    "    bad = True\n",
    "    while bad:\n",
    "        bad = False\n",
    "        for k in range(len(choice)):\n",
    "            for l in range(k):\n",
    "                if np.abs(cor[choice[k]][choice[l]]) > 0.75:\n",
    "                    bad = True\n",
    "                    break\n",
    "            if bad:\n",
    "                break\n",
    "        if bad:\n",
    "            choice = random.sample(range(d.shape[0]), n)\n",
    "\n",
    "    s = d[choice].sum(axis=0)\n",
    "    s = s / n\n",
    "    m = s.mean()\n",
    "    s = s / m\n",
    "    x = np.arange(len(s)) + 1\n",
    "    a, b = np.polyfit(x, np.log(s), 1)\n",
    "    y = np.exp(a * x + b)\n",
    "\n",
    "    # reg times\n",
    "    last = s[0] < y[0]\n",
    "    reg = 0\n",
    "    regDist = [0]\n",
    "    for i in range(1, len(s)):\n",
    "        if (s[i] < y[i]) != last:\n",
    "            regDist.append(i)\n",
    "            reg += 1\n",
    "            last = s[i] < y[i]\n",
    "\n",
    "    # reg distribution\n",
    "    regDist = np.array(regDist)\n",
    "    regStd = (regDist[1:] - regDist[:-1]).std()\n",
    "    dist.append(regStd)\n",
    "    \n",
    "pandas.DataFrame(dist).hist(bins=1000)\n",
    "pandas.qcut(dist,  [0, 0.05, 0.1, 0.25, 0.5, 0.75, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weekly data and clean into d.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "df = None\n",
    "for f in glob('D:\\\\work\\\\main\\\\IB\\\\*_week.csv'):\n",
    "    if df is None:\n",
    "        df = pandas.read_csv(f, index_col=0).T\n",
    "    else:\n",
    "        df = pandas.concat([df,pandas.read_csv(f, index_col=0).T], axis=1)\n",
    "\n",
    "d = df.iloc[-112:-1,:]\n",
    "d = d.dropna(axis=1,how='any').astype('float32').T\n",
    "d.to_csv('d.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "daily = None\n",
    "for f in glob('D:\\\\work\\\\main\\\\IB\\\\*_day.csv'):\n",
    "    if daily is None:\n",
    "        daily = pandas.read_csv(f, index_col=0).T\n",
    "    else:\n",
    "        daily = pandas.concat([daily,pandas.read_csv(f, index_col=0).T], axis=1)\n",
    "daily.to_csv('day.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test by day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "daily = pandas.read_csv('day.csv', index_col=0)[columns].T\n",
    "print(columns)\n",
    "moneyNeeded = 100 / (p[idx]/p[idx].sum()/daily.T.iloc[-1,:].values)[2]\n",
    "tobuy = np.round(moneyNeeded * p[idx]/p[idx].sum() /  daily.T.iloc[-1,:].values)\n",
    "moneyNeeded = tobuy * daily.T.iloc[-1,:].values\n",
    "print('shares ', str(tobuy), tobuy.sum(), moneyNeeded)\n",
    "moneyNeeded = moneyNeeded.sum()\n",
    "print(moneyNeeded)\n",
    "\n",
    "a = daily.iloc[:, :-1]\n",
    "b = daily.iloc[:, 1:]\n",
    "a.columns = b.columns\n",
    "r = ((b / a - 1).T * p[idx] ).T\n",
    "print(r.shape)\n",
    "\n",
    "dates = daily.columns.astype(np.float32)\n",
    "dates = np.round((dates - startDate) / 3600 / 24 / 1000) / 7 + 1\n",
    "base = 10.4\n",
    "r = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                    np.add.accumulate(r, axis=1) + np.ones(r.shape) * base), axis=1).T\n",
    "r = pandas.DataFrame(r)\n",
    "r.columns = columns\n",
    "r.index = dates\n",
    "r.plot(figsize=(16,9))\n",
    "\n",
    "y = np.exp(A * dates + B) * moneyNeeded / 10\n",
    "y2 = r.sum(axis=1) / len(columns) * moneyNeeded / 10\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(dates, y)\n",
    "plt.plot(dates, y2)\n",
    "#plt.plot(111, np.exp(A * 111 + B), marker='o', color='r', ls='')\n",
    "#y2[-1] / y[-1] - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
