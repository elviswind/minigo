{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# test area\n",
    "np.maximum.accumulate([1,2,3,1,5])\n",
    "np.power(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df = pandas.read_csv('d.csv', index_col=0)\n",
    "names = df.index\n",
    "columns = df.columns\n",
    "\n",
    "a = df.iloc[:, :-1]\n",
    "b = df.iloc[:, 1:]\n",
    "b.columns = a.columns\n",
    "r = (b - a) / a\n",
    "r = r.values\n",
    "base = 10\n",
    "df = pandas.DataFrame(np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                np.add.accumulate(r * base, axis=1) + np.ones(r.shape) * base), axis=1))\n",
    "df.index = names\n",
    "df.columns = columns\n",
    "\n",
    "origin = df.copy()\n",
    "for i in range(2, 11):\n",
    "    n = origin.copy() * i\n",
    "    n.index = map(lambda x: str(i) + x, origin.index)\n",
    "    df = pandas.concat([df, n])\n",
    "\n",
    "l = df.shape[0]\n",
    "correlation = np.ones([l, l])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d = df.values\n",
    "df.index[[7, 7+71]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.array([list(d[6]), list(d[64])])\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "w = tf.get_variable(\"weight\", [V.shape[0], 1], tf.float32, initializer=tf.truncated_normal_initializer)\n",
    "a = tf.get_variable(\"a\", [1], tf.float32, initializer=tf.truncated_normal_initializer)\n",
    "b = tf.constant(10, tf.float32)\n",
    "\n",
    "\n",
    "x = np.arange(V.shape[1])\n",
    "y = a * x + b\n",
    "\n",
    "v = tf.constant(V, tf.float32)\n",
    "s = tf.reduce_sum(w * v, axis=0)\n",
    "\n",
    "loss = tf.reduce_sum(tf.pow(s - y, 2))\n",
    "total_loss = loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1)\n",
    "train_op = optimizer.minimize(total_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for step in range(10000000):\n",
    "        sess.run(train_op)\n",
    "        if step % 3000 == 0:\n",
    "            print(step)\n",
    "            print(sess.run(a))\n",
    "            print(sess.run(w))\n",
    "            print(sess.run(s))\n",
    "            print(sess.run(y))\n",
    "            print(sess.run(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[0.27],[0.66]])\n",
    "s = (w * V).sum(axis=0)\n",
    "s = s / s[0] * 10\n",
    "graph = np.concatenate([V, [s]], axis=0).T\n",
    "pandas.DataFrame(graph).plot()\n",
    "pandas.DataFrame(d[64]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latest = np.load('lasttime.npy')\n",
    "print(latest.shape)\n",
    "print(latest[0:3])\n",
    "print(latest[-3:])\n",
    "\n",
    "dict = {}\n",
    "for a in latest:\n",
    "    for b in a[0]:\n",
    "        if b in dict:\n",
    "            dict[b] += 1\n",
    "        else:\n",
    "            dict[b] = 1\n",
    "x = []\n",
    "for key in dict:\n",
    "    x.append([key, dict[key]])\n",
    "x = sorted(x, key=lambda m: m[1], reverse=True)\n",
    "\n",
    "for y in x[:500]:\n",
    "    print(df.index[y[0]], y[0], y[1])\n",
    "\n",
    "\n",
    "for a in latest:\n",
    "    if 6 in a[0]:\n",
    "        print(list(df.index[a[0]]), a)\n",
    "    \n",
    "for a in latest[0:10]:\n",
    "    print(list(df.index[a[0]]), a)\n",
    "\n",
    "idx = latest[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a in latest:\n",
    "    s = (d[a[0]]).sum(axis=0)\n",
    "    drop = 1 - s / np.maximum.accumulate(s)\n",
    "    drop_i = np.argsort(drop)\n",
    "    def getIJ(ij, i):\n",
    "        return ij[i], np.argmax(s[:ij[i]])\n",
    "\n",
    "    i, j = getIJ(drop_i, -1)     \n",
    "    if drop[i] < 0.01:\n",
    "        print('max drawback {:0.2f}% {:0.2f} {:0.2f} {} {}'.format(drop[i] * 100, s[i], s[j], i, j))\n",
    "        print('average drop', drop.mean())\n",
    "        print(list(df.index[a[0]]), a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test By tiger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = [6, 166, 166, 341, 466, 705]\n",
    "columns = list(np.array(df.index)[idx])\n",
    "print(columns)\n",
    "\n",
    "dates = df.columns.astype(np.float32)\n",
    "startDate = dates[0]\n",
    "dates = np.round((dates - startDate) / 3600 / 24 / 1000 / 7) + 1\n",
    "\n",
    "\n",
    "\n",
    "# basic info\n",
    "a = d[idx][:, 1:]\n",
    "b = d[idx][:, :-1]\n",
    "r = a - b\n",
    "contri= np.abs(r).mean(axis=1)\n",
    "contri = contri / contri.min()\n",
    "print(\"contribution: {}\".format(contri))\n",
    "\n",
    "graph = pandas.DataFrame(d[idx]).T\n",
    "graph.columns = columns \n",
    "graph.plot()\n",
    "\n",
    "s = (d[idx]).sum(axis=0)\n",
    "def evaluate(s, dates, components):\n",
    "    # regression \n",
    "    s = s / len(idx)\n",
    "    A, B = np.polyfit(dates, np.log(s), 1)\n",
    "    print('A,B', A, B)\n",
    "    y = np.exp(A * dates + B)\n",
    "    last = s[0] < y[0]\n",
    "    reg = 0\n",
    "    for i in range(1, len(s)):\n",
    "        if (s[i] < y[i]) != last:\n",
    "            reg += 1\n",
    "            last = s[i] < y[i]\n",
    "    print('revisit times: ', reg)\n",
    "    \n",
    "    loss = (((y - s) / s) ** 2)\n",
    "    print('loss: ', np.array(loss).sum())\n",
    "    print(y[-1] / y[0] - 1)\n",
    "\n",
    "\n",
    "    # max drawback \n",
    "    drop = 1 - s / np.maximum.accumulate(s)\n",
    "    drop_i = np.argsort(drop)\n",
    "    def getIJ(ij, i):\n",
    "        return ij[i], np.argmax(s[:ij[i]])\n",
    "\n",
    "    i, j = getIJ(drop_i, -1)     \n",
    "    print('max drawback {:0.2f}% {:0.2f} {:0.2f} {} {}'.format(drop[i] * 100, s[i], s[j], i, j))\n",
    "    print('average drop', drop.mean())\n",
    "    pandas.DataFrame(drop).hist(bins=20)\n",
    "\n",
    "\n",
    "    print(s[-1])\n",
    "    print(dates[-1])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(dates, y)\n",
    "    plt.plot(dates, s)\n",
    "    plt.plot([i+1,j+1], [s[i], s[j]], 'o', color='Red', markersize=4)\n",
    "\n",
    "    plt.figure(figsize=(9,25))\n",
    "    plt.plot(dates, y)\n",
    "    plt.plot(dates, s)\n",
    "    if components is not None:\n",
    "        plots = []\n",
    "        for x in range(len(components.values.T)):\n",
    "            plots.append(plt.plot(dates, components.values.T[x], label=components.columns[x])[0])\n",
    "        plt.legend(handles=plots)\n",
    "    plt.plot([i+1,j+1], [s[i], s[j]], 'o', color='Red', markersize=4)\n",
    "\n",
    "    i2, j2 = getIJ(drop_i, -2)\n",
    "    plt.plot([i2+1,j2+1], [s[i2], s[j2]], 'o', color='Blue', markersize=4)\n",
    "\n",
    "evaluate(s, dates, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = list(np.array(df.index)[idx])\n",
    "print(columns)\n",
    "names = list(map(lambda c: c.split('#')[1], columns))\n",
    "\n",
    "df2 = None\n",
    "for n in names:\n",
    "    f = '/Users/junnwang/Downloads/csv 2/' + n + '_week.csv'\n",
    "    if df2 is None:\n",
    "        df2 = pandas.read_csv(f, index_col=0).T\n",
    "    else:\n",
    "        df2 = pandas.concat([df2,pandas.read_csv(f, index_col=0).T], axis=1)\n",
    "print(df2.dropna(axis=0,how='any').astype('float32').shape)     \n",
    "df2 = df2.iloc[-160:,:]\n",
    "d2 = df2.dropna(axis=1,how='any').astype('float32').T\n",
    "a = d2.iloc[:, :-1]\n",
    "b = d2.iloc[:, 1:]\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "b.columns = a.columns = range(d2.shape[1] - 1)\n",
    "r = (b - a) / a\n",
    "p2 = p[idx]\n",
    "r = (r.T * p2).T.values\n",
    "\n",
    "\n",
    "dates = d2.columns.astype(np.float32)\n",
    "startDate = dates[0]\n",
    "dates = np.round((dates - startDate) / 3600 / 24 / 1000 / 7) + 1\n",
    "\n",
    "dd2 = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                        np.add.accumulate(r, axis=1) + np.ones(r.shape) * base), axis=1)\n",
    "\n",
    "s = dd2.sum(axis=0)\n",
    "print(\"percentage of total value: {}\".format(p2 / p2.sum() * 100))\n",
    "\n",
    "dd2 = pandas.DataFrame(dd2.T)\n",
    "dd2.columns = columns\n",
    "evaluate(s, dates, dd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test by yahoo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "df = None\n",
    "for f in glob('sss\\\\*.csv'):\n",
    "    name = f.split('\\\\')[1].split('.')[0]\n",
    "    if df is None:\n",
    "        df = pandas.read_csv(f, index_col=0)[['Adj Close']]\n",
    "        df.columns = [name]\n",
    "    else:\n",
    "        csv = pandas.read_csv(f, index_col=0)[['Adj Close']]\n",
    "        csv.columns = [name]\n",
    "        df = pandas.concat([df,csv], axis=1)\n",
    "        \n",
    "df = df.dropna().T\n",
    "print(df.shape)\n",
    "a = df.iloc[:, :-1]\n",
    "b = df.iloc[:, 1:]\n",
    "b.columns = a.columns\n",
    "r = (((b - a) / a).T * p[idx] ).T\n",
    "r = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                    np.add.accumulate(r, axis=1) + np.ones(r.shape) * base), axis=1).T\n",
    "r = pandas.DataFrame(r)\n",
    "r.index = df.columns.astype(np.datetime64)\n",
    "r.columns = df.index\n",
    "r.plot(figsize=(16, 9))\n",
    "print(r.shape)\n",
    "\n",
    "y2 = r.sum(axis=1)\n",
    "#plt.figure(figsize=(16, 9))\n",
    "plt.plot(df.columns.astype(np.datetime64), y2 / len(idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test random output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import dao\n",
    "\n",
    "dist = []\n",
    "n = 6\n",
    "for i in range(500000):\n",
    "    choice = random.sample(range(d.shape[0]), n)\n",
    "#     bad = True\n",
    "#     while bad:\n",
    "#         bad = False\n",
    "#         for k in range(len(choice)):\n",
    "#             for l in range(k):\n",
    "#                 if np.abs(correlation[choice[k]][choice[l]]) == 0:\n",
    "#                     bad = True\n",
    "#                     break\n",
    "#             if bad:\n",
    "#                 break\n",
    "#         if bad:\n",
    "#             choice = random.sample(range(d.shape[0]), n)\n",
    "\n",
    "    result = dao.test_choice(choice)\n",
    "    dist.append(result[1])\n",
    "    \n",
    "pandas.DataFrame(dist).hist(bins=1000)\n",
    "pandas.qcut(dist,  [0, 0.05, 0.1, 0.25, 0.5, 0.75, 0.999, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weekly data and clean into d.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "search = ['SPY','EEM','QQQ','HYG','IWM','XLF','VXX','UVXY','EFA','FXI','EWZ','TLT','GLD','FEZ','SMH','USO','SLV','GDX','XLI','XLE','DIA','XRT','XOP','KRE','AAPL','BAC','BABA','TSLA','FB','AMZN','GE','AMD','MU','C','INTC','AABA','EA','JPM','F','NXPI','NFLX','TWTR','MSFT','FOXA','SNAP','WYNN','GM','CAT','WFC','X','T','JD','PBR','QCOM','USB','AA','WMT','DBX','AAL','BA','CMCSA','BIDU','KMI','MS','MET','FCX','NVDA','M','SQ','GS','V','BK','DB']\n",
    "\n",
    "df = None\n",
    "# for f in glob('D:\\\\work\\\\main\\\\IB\\\\csv\\\\*_week.csv'):\n",
    "#     if df is None:\n",
    "#         df = pandas.read_csv(f, index_col=0).T\n",
    "#     else:\n",
    "#         df = pandas.concat([df,pandas.read_csv(f, index_col=0).T], axis=1)\n",
    "for s in search:\n",
    "    f = 'D:\\\\work\\\\main\\\\IB\\\\csv\\\\' + s + '_week.csv'\n",
    "    if df is None:\n",
    "        df = pandas.read_csv(f, index_col=0).T\n",
    "    else:\n",
    "        df = pandas.concat([df,pandas.read_csv(f, index_col=0).T], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "d = df.iloc[-112:-1,:]\n",
    "d = d.dropna(axis=1,how='any').astype('float32').T\n",
    "print(d.shape)\n",
    "d.to_csv('d.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "daily = None\n",
    "for f in glob('D:\\\\work\\\\main\\\\IB\\\\*_day.csv'):\n",
    "    if daily is None:\n",
    "        daily = pandas.read_csv(f, index_col=0).T\n",
    "    else:\n",
    "        daily = pandas.concat([daily,pandas.read_csv(f, index_col=0).T], axis=1)\n",
    "daily.to_csv('day.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test by day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "daily = pandas.read_csv('day.csv', index_col=0)[columns].T\n",
    "print(columns)\n",
    "moneyNeeded = 100 / (p[idx]/p[idx].sum()/daily.T.iloc[-1,:].values)[2]\n",
    "tobuy = np.round(moneyNeeded * p[idx]/p[idx].sum() /  daily.T.iloc[-1,:].values)\n",
    "moneyNeeded = tobuy * daily.T.iloc[-1,:].values\n",
    "print('shares ', str(tobuy), tobuy.sum(), moneyNeeded)\n",
    "moneyNeeded = moneyNeeded.sum()\n",
    "print(moneyNeeded)\n",
    "\n",
    "a = daily.iloc[:, :-1]\n",
    "b = daily.iloc[:, 1:]\n",
    "a.columns = b.columns\n",
    "r = ((b / a - 1).T * p[idx] ).T\n",
    "print(r.shape)\n",
    "\n",
    "dates = daily.columns.astype(np.float32)\n",
    "dates = np.round((dates - startDate) / 3600 / 24 / 1000) / 7 + 1\n",
    "base = 10.4\n",
    "r = np.concatenate((np.ones([r.shape[0], 1]) * base,\n",
    "                    np.add.accumulate(r, axis=1) + np.ones(r.shape) * base), axis=1).T\n",
    "r = pandas.DataFrame(r)\n",
    "r.columns = columns\n",
    "r.index = dates\n",
    "r.plot(figsize=(16,9))\n",
    "\n",
    "y = np.exp(A * dates + B) * moneyNeeded / 10\n",
    "y2 = r.sum(axis=1) / len(columns) * moneyNeeded / 10\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(dates, y)\n",
    "plt.plot(dates, y2)\n",
    "#plt.plot(111, np.exp(A * 111 + B), marker='o', color='r', ls='')\n",
    "#y2[-1] / y[-1] - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
